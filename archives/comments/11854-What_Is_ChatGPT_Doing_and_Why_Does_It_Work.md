# title
What Is ChatGPT Doing … and Why Does It Work?

# author
Stephen Wolfram

# publisher
stephenwolfram.com

# date
2023-02

# chapter
列传

# tag
AI, Neutral Net, ChatGPT

# remarks
`学到了一点点`

Transformer:

Positional Encoding: 为了更容易train, 更能parallel. 不是说结构必须第一个词第二个词, 而是只是第一个词带一个1, 第二个词带一个2

Attention: when translating everyword, it can look at all original words, with weights

Self-Attention: in understanding words, e.g. in the original training corpus or prompt, it will put word together with surrounding context. Not just individually

